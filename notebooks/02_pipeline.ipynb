{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91414074",
   "metadata": {},
   "source": [
    "# Entrenamiento Higgs → WW* \n",
    "\n",
    "## Objetivo\n",
    "Pipeline end-to-end para entrenar modelo de clasificación Higgs vs DibosonWW usando:\n",
    "- Datos pre-procesados y guardados\n",
    "- Validación cruzada estratificada (5-fold)\n",
    "- Feature engineering + selection automática\n",
    "- Boosting (XGBoost/LightGBM)\n",
    "- Métricas HEP (ROC-AUC, AMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cc939f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.data.merge_data import merge_and_save\n",
    "from src.data.fold_split import generate_folds\n",
    "from src.models.trainer import train_with_folds, train_final_model\n",
    "from src.features.feature_engineering import add_feature_engineering\n",
    "from collections import Counter\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae008d",
   "metadata": {},
   "source": [
    "## Importamos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c21ddbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Shape: (26277, 35)\n",
      "   Clases: {0: 14937, 1: 11340}\n",
      "\n",
      " Dataset listo para pipeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigE</th>\n",
       "      <th>trigM</th>\n",
       "      <th>lep_n</th>\n",
       "      <th>jet_n</th>\n",
       "      <th>met_et</th>\n",
       "      <th>met_phi</th>\n",
       "      <th>lep_pt_0</th>\n",
       "      <th>lep_pt_1</th>\n",
       "      <th>lep_eta_0</th>\n",
       "      <th>lep_eta_1</th>\n",
       "      <th>...</th>\n",
       "      <th>jet_eta</th>\n",
       "      <th>jet_phi</th>\n",
       "      <th>jet_E</th>\n",
       "      <th>jet_MV2c10</th>\n",
       "      <th>sample</th>\n",
       "      <th>mLL</th>\n",
       "      <th>pTll</th>\n",
       "      <th>dphi_ll</th>\n",
       "      <th>dphi_ll_met</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39938.445</td>\n",
       "      <td>1.856930</td>\n",
       "      <td>39422.570312</td>\n",
       "      <td>26516.251953</td>\n",
       "      <td>0.571867</td>\n",
       "      <td>-0.233551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>WW</td>\n",
       "      <td>46.733593</td>\n",
       "      <td>53.660680</td>\n",
       "      <td>1.268602</td>\n",
       "      <td>3.098009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>44835.996</td>\n",
       "      <td>-2.870015</td>\n",
       "      <td>55275.070312</td>\n",
       "      <td>29202.830078</td>\n",
       "      <td>0.167149</td>\n",
       "      <td>0.127004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525750</td>\n",
       "      <td>2.928067</td>\n",
       "      <td>72089.546875</td>\n",
       "      <td>-0.842718</td>\n",
       "      <td>WW</td>\n",
       "      <td>26.723835</td>\n",
       "      <td>80.155811</td>\n",
       "      <td>0.676783</td>\n",
       "      <td>2.675013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>85033.480</td>\n",
       "      <td>0.415477</td>\n",
       "      <td>51790.308594</td>\n",
       "      <td>20564.869141</td>\n",
       "      <td>-0.560513</td>\n",
       "      <td>-0.214823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278951</td>\n",
       "      <td>-1.938559</td>\n",
       "      <td>21311.076172</td>\n",
       "      <td>-0.690779</td>\n",
       "      <td>Higgs</td>\n",
       "      <td>12.353210</td>\n",
       "      <td>72.188777</td>\n",
       "      <td>0.150418</td>\n",
       "      <td>2.628970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trigE  trigM  lep_n  jet_n     met_et   met_phi      lep_pt_0  \\\n",
       "0   True   True      2      0  39938.445  1.856930  39422.570312   \n",
       "1   True   True      2      1  44835.996 -2.870015  55275.070312   \n",
       "2   True  False      2      1  85033.480  0.415477  51790.308594   \n",
       "\n",
       "       lep_pt_1  lep_eta_0  lep_eta_1  ...   jet_eta   jet_phi         jet_E  \\\n",
       "0  26516.251953   0.571867  -0.233551  ...  0.000000  0.000000      0.000000   \n",
       "1  29202.830078   0.167149   0.127004  ...  0.525750  2.928067  72089.546875   \n",
       "2  20564.869141  -0.560513  -0.214823  ... -0.278951 -1.938559  21311.076172   \n",
       "\n",
       "   jet_MV2c10  sample        mLL       pTll   dphi_ll  dphi_ll_met  target  \n",
       "0    0.000000      WW  46.733593  53.660680  1.268602     3.098009       0  \n",
       "1   -0.842718      WW  26.723835  80.155811  0.676783     2.675013       0  \n",
       "2   -0.690779   Higgs  12.353210  72.188777  0.150418     2.628970       1  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_path = \"../data/interim/merged_raw.pkl\"\n",
    "\n",
    "merged_df = pd.read_pickle(merged_path)\n",
    "print(f\"   Shape: {merged_df.shape}\")\n",
    "print(f\"   Clases: {merged_df['target'].value_counts().to_dict()}\")\n",
    "\n",
    "print(\"\\n Dataset listo para pipeline\")\n",
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80bcc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds ya generados en ../data/interim/folded/\n",
      "Total archivos: 10\n"
     ]
    }
   ],
   "source": [
    "# Generar folds si no existen\n",
    "folds_dir = \"../data/interim/folded/\"\n",
    "\n",
    "if os.path.exists(folds_dir) and len(os.listdir(folds_dir)) > 0:\n",
    "    print(f\"Folds ya generados en {folds_dir}\")\n",
    "    print(f\"Total archivos: {len(os.listdir(folds_dir))}\")\n",
    "else:\n",
    "    print(\"Generando folds estratificados...\")\n",
    "    generate_folds(\n",
    "        merged_path=merged_path,\n",
    "        output_dir=folds_dir,\n",
    "        n_splits=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(f\"Folds guardados en {folds_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d73e2d",
   "metadata": {},
   "source": [
    "## Folds Estratificados\n",
    "\n",
    "Crea 5 folds con StratifiedKFold para mantener proporciones señal/fondo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ce903b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con validación cruzada...\n",
      "\n",
      " Entrenamiento por folds\n",
      "\n",
      "\n",
      "FOLD 1\n",
      "\n",
      "\n",
      "========== SELECCIÓN DE VARIABLES COMBINADA ==========\n",
      "\n",
      "Calculando Mutual Information...\n",
      "Entrenando XGBoost para importancia de variables...\n",
      "Entrenando XGBoost para importancia de variables...\n",
      "Calculando Permutation Importance...\n",
      "Calculando Permutation Importance...\n",
      "\n",
      "Variables seleccionadas:\n",
      "- MT_ll_met\n",
      "- cluster_mass\n",
      "- met_et\n",
      "- mLL\n",
      "- ptll_met\n",
      "- E_sum_ll\n",
      "- curr_mt\n",
      "- lep_pt_1\n",
      "- delta_R_ll\n",
      "- pTll\n",
      "- lep_E_1\n",
      "- jet_pt\n",
      "- pt_sum_ll\n",
      "- pt_balance\n",
      "- jet_eta\n",
      "Entrenando modelo...\n",
      "[LightGBM] [Info] Number of positive: 9072, number of negative: 11949\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 21021, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431568 -> initscore=-0.275455\n",
      "[LightGBM] [Info] Start training from score -0.275455\n",
      "\n",
      "Variables seleccionadas:\n",
      "- MT_ll_met\n",
      "- cluster_mass\n",
      "- met_et\n",
      "- mLL\n",
      "- ptll_met\n",
      "- E_sum_ll\n",
      "- curr_mt\n",
      "- lep_pt_1\n",
      "- delta_R_ll\n",
      "- pTll\n",
      "- lep_E_1\n",
      "- jet_pt\n",
      "- pt_sum_ll\n",
      "- pt_balance\n",
      "- jet_eta\n",
      "Entrenando modelo...\n",
      "[LightGBM] [Info] Number of positive: 9072, number of negative: 11949\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 21021, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431568 -> initscore=-0.275455\n",
      "[LightGBM] [Info] Start training from score -0.275455\n",
      "Métricas fold 1: {'AUC': 0.7455409527587127, 'Accuracy': 0.67941400304414, 'F1': 0.63425222487519, 'TP': np.int64(1461), 'FP': np.int64(878), 'AMS': 0.0}\n",
      "\n",
      "FOLD 2\n",
      "\n",
      "Métricas fold 1: {'AUC': 0.7455409527587127, 'Accuracy': 0.67941400304414, 'F1': 0.63425222487519, 'TP': np.int64(1461), 'FP': np.int64(878), 'AMS': 0.0}\n",
      "\n",
      "FOLD 2\n",
      "\n",
      "\n",
      "========== SELECCIÓN DE VARIABLES COMBINADA ==========\n",
      "\n",
      "Calculando Mutual Information...\n",
      "\n",
      "========== SELECCIÓN DE VARIABLES COMBINADA ==========\n",
      "\n",
      "Calculando Mutual Information...\n",
      "Entrenando XGBoost para importancia de variables...\n",
      "Entrenando XGBoost para importancia de variables...\n",
      "Calculando Permutation Importance...\n",
      "Calculando Permutation Importance...\n",
      "\n",
      "Variables seleccionadas:\n",
      "- MT_ll_met\n",
      "- cluster_mass\n",
      "- mLL\n",
      "- met_et\n",
      "- jet_pt\n",
      "- ptll_met\n",
      "- delta_R_ll\n",
      "- pTll\n",
      "- lep_pt_1\n",
      "- lep_E_1\n",
      "- E_sum_ll\n",
      "- pt_sum_ll\n",
      "- curr_mt\n",
      "- jet_MV2c10\n",
      "- pt_ratio\n",
      "Entrenando modelo...\n",
      "[LightGBM] [Info] Number of positive: 9072, number of negative: 11949\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 21021, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431568 -> initscore=-0.275455\n",
      "[LightGBM] [Info] Start training from score -0.275455\n",
      "\n",
      "Variables seleccionadas:\n",
      "- MT_ll_met\n",
      "- cluster_mass\n",
      "- mLL\n",
      "- met_et\n",
      "- jet_pt\n",
      "- ptll_met\n",
      "- delta_R_ll\n",
      "- pTll\n",
      "- lep_pt_1\n",
      "- lep_E_1\n",
      "- E_sum_ll\n",
      "- pt_sum_ll\n",
      "- curr_mt\n",
      "- jet_MV2c10\n",
      "- pt_ratio\n",
      "Entrenando modelo...\n",
      "[LightGBM] [Info] Number of positive: 9072, number of negative: 11949\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 21021, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431568 -> initscore=-0.275455\n",
      "[LightGBM] [Info] Start training from score -0.275455\n",
      "Métricas fold 2: {'AUC': 0.7451276298610079, 'Accuracy': 0.681316590563166, 'F1': 0.6433893974877581, 'TP': np.int64(1511), 'FP': np.int64(918), 'AMS': 0.0}\n",
      "\n",
      "FOLD 3\n",
      "\n",
      "Métricas fold 2: {'AUC': 0.7451276298610079, 'Accuracy': 0.681316590563166, 'F1': 0.6433893974877581, 'TP': np.int64(1511), 'FP': np.int64(918), 'AMS': 0.0}\n",
      "\n",
      "FOLD 3\n",
      "\n",
      "\n",
      "========== SELECCIÓN DE VARIABLES COMBINADA ==========\n",
      "\n",
      "Calculando Mutual Information...\n",
      "\n",
      "========== SELECCIÓN DE VARIABLES COMBINADA ==========\n",
      "\n",
      "Calculando Mutual Information...\n",
      "Entrenando XGBoost para importancia de variables...\n",
      "Entrenando XGBoost para importancia de variables...\n",
      "Calculando Permutation Importance...\n",
      "Calculando Permutation Importance...\n",
      "\n",
      "Variables seleccionadas:\n",
      "- MT_ll_met\n",
      "- cluster_mass\n",
      "- mLL\n",
      "- delta_R_ll\n",
      "- E_sum_ll\n",
      "- lep_pt_1\n",
      "- met_et\n",
      "- pTll\n",
      "- ptll_met\n",
      "- curr_mt\n",
      "- pt_sum_ll\n",
      "- jet_pt\n",
      "- jet_MV2c10\n",
      "- pt_balance\n",
      "- pt_ratio\n",
      "Entrenando modelo...\n",
      "[LightGBM] [Info] Number of positive: 9072, number of negative: 11950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 21022, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431548 -> initscore=-0.275539\n",
      "[LightGBM] [Info] Start training from score -0.275539\n",
      "\n",
      "Variables seleccionadas:\n",
      "- MT_ll_met\n",
      "- cluster_mass\n",
      "- mLL\n",
      "- delta_R_ll\n",
      "- E_sum_ll\n",
      "- lep_pt_1\n",
      "- met_et\n",
      "- pTll\n",
      "- ptll_met\n",
      "- curr_mt\n",
      "- pt_sum_ll\n",
      "- jet_pt\n",
      "- jet_MV2c10\n",
      "- pt_balance\n",
      "- pt_ratio\n",
      "Entrenando modelo...\n",
      "[LightGBM] [Info] Number of positive: 9072, number of negative: 11950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 21022, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431548 -> initscore=-0.275539\n",
      "[LightGBM] [Info] Start training from score -0.275539\n",
      "Métricas fold 3: {'AUC': 0.7487578448408712, 'Accuracy': 0.6782112274024739, 'F1': 0.6442247001893541, 'TP': np.int64(1531), 'FP': np.int64(954), 'AMS': 0.0}\n",
      "\n",
      "FOLD 4\n",
      "\n",
      "Métricas fold 3: {'AUC': 0.7487578448408712, 'Accuracy': 0.6782112274024739, 'F1': 0.6442247001893541, 'TP': np.int64(1531), 'FP': np.int64(954), 'AMS': 0.0}\n",
      "\n",
      "FOLD 4\n",
      "\n",
      "\n",
      "========== SELECCIÓN DE VARIABLES COMBINADA ==========\n",
      "\n",
      "Calculando Mutual Information...\n",
      "\n",
      "========== SELECCIÓN DE VARIABLES COMBINADA ==========\n",
      "\n",
      "Calculando Mutual Information...\n",
      "Entrenando XGBoost para importancia de variables...\n",
      "Entrenando XGBoost para importancia de variables...\n",
      "Calculando Permutation Importance...\n",
      "Calculando Permutation Importance...\n",
      "\n",
      "Variables seleccionadas:\n",
      "- MT_ll_met\n",
      "- cluster_mass\n",
      "- mLL\n",
      "- met_et\n",
      "- ptll_met\n",
      "- E_sum_ll\n",
      "- jet_pt\n",
      "- lep_pt_1\n",
      "- delta_R_ll\n",
      "- pTll\n",
      "- curr_mt\n",
      "- pt_sum_ll\n",
      "- lep_E_1\n",
      "- lep_pt_0\n",
      "- trigM\n",
      "Entrenando modelo...\n",
      "[LightGBM] [Info] Number of positive: 9072, number of negative: 11950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3572\n",
      "[LightGBM] [Info] Number of data points in the train set: 21022, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431548 -> initscore=-0.275539\n",
      "[LightGBM] [Info] Start training from score -0.275539\n",
      "\n",
      "Variables seleccionadas:\n",
      "- MT_ll_met\n",
      "- cluster_mass\n",
      "- mLL\n",
      "- met_et\n",
      "- ptll_met\n",
      "- E_sum_ll\n",
      "- jet_pt\n",
      "- lep_pt_1\n",
      "- delta_R_ll\n",
      "- pTll\n",
      "- curr_mt\n",
      "- pt_sum_ll\n",
      "- lep_E_1\n",
      "- lep_pt_0\n",
      "- trigM\n",
      "Entrenando modelo...\n",
      "[LightGBM] [Info] Number of positive: 9072, number of negative: 11950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3572\n",
      "[LightGBM] [Info] Number of data points in the train set: 21022, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431548 -> initscore=-0.275539\n",
      "[LightGBM] [Info] Start training from score -0.275539\n",
      "Métricas fold 4: {'AUC': 0.7412339125038601, 'Accuracy': 0.6782112274024739, 'F1': 0.6409004034826927, 'TP': np.int64(1509), 'FP': np.int64(932), 'AMS': 0.0}\n",
      "\n",
      "FOLD 5\n",
      "\n",
      "Métricas fold 4: {'AUC': 0.7412339125038601, 'Accuracy': 0.6782112274024739, 'F1': 0.6409004034826927, 'TP': np.int64(1509), 'FP': np.int64(932), 'AMS': 0.0}\n",
      "\n",
      "FOLD 5\n",
      "\n",
      "\n",
      "========== SELECCIÓN DE VARIABLES COMBINADA ==========\n",
      "\n",
      "Calculando Mutual Information...\n",
      "\n",
      "========== SELECCIÓN DE VARIABLES COMBINADA ==========\n",
      "\n",
      "Calculando Mutual Information...\n",
      "Entrenando XGBoost para importancia de variables...\n",
      "Entrenando XGBoost para importancia de variables...\n",
      "Calculando Permutation Importance...\n",
      "Calculando Permutation Importance...\n",
      "\n",
      "Variables seleccionadas:\n",
      "- MT_ll_met\n",
      "- cluster_mass\n",
      "- mLL\n",
      "- met_et\n",
      "- ptll_met\n",
      "- jet_pt\n",
      "- E_sum_ll\n",
      "- pTll\n",
      "- curr_mt\n",
      "- delta_R_ll\n",
      "- lep_pt_1\n",
      "- lep_E_1\n",
      "- pt_sum_ll\n",
      "- pt_ratio\n",
      "- lep_pt_0\n",
      "Entrenando modelo...\n",
      "[LightGBM] [Info] Number of positive: 9072, number of negative: 11950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 21022, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431548 -> initscore=-0.275539\n",
      "[LightGBM] [Info] Start training from score -0.275539\n",
      "\n",
      "Variables seleccionadas:\n",
      "- MT_ll_met\n",
      "- cluster_mass\n",
      "- mLL\n",
      "- met_et\n",
      "- ptll_met\n",
      "- jet_pt\n",
      "- E_sum_ll\n",
      "- pTll\n",
      "- curr_mt\n",
      "- delta_R_ll\n",
      "- lep_pt_1\n",
      "- lep_E_1\n",
      "- pt_sum_ll\n",
      "- pt_ratio\n",
      "- lep_pt_0\n",
      "Entrenando modelo...\n",
      "[LightGBM] [Info] Number of positive: 9072, number of negative: 11950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 21022, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431548 -> initscore=-0.275539\n",
      "[LightGBM] [Info] Start training from score -0.275539\n",
      "Métricas fold 5: {'AUC': 0.7402362028519823, 'Accuracy': 0.6747859181731685, 'F1': 0.6372320101889195, 'TP': np.int64(1501), 'FP': np.int64(942), 'AMS': 0.0}\n",
      "\n",
      " Entrenamiento por folds completado\n",
      "\n",
      "\n",
      "Resultados por fold:\n",
      "   fold                        model_path       AUC  Accuracy        F1    TP  \\\n",
      "0     1  ../models/folds/model_fold_1.pkl  0.745541  0.679414  0.634252  1461   \n",
      "1     2  ../models/folds/model_fold_2.pkl  0.745128  0.681317  0.643389  1511   \n",
      "2     3  ../models/folds/model_fold_3.pkl  0.748758  0.678211  0.644225  1531   \n",
      "3     4  ../models/folds/model_fold_4.pkl  0.741234  0.678211  0.640900  1509   \n",
      "4     5  ../models/folds/model_fold_5.pkl  0.740236  0.674786  0.637232  1501   \n",
      "\n",
      "    FP  AMS  \n",
      "0  878  0.0  \n",
      "1  918  0.0  \n",
      "2  954  0.0  \n",
      "3  932  0.0  \n",
      "4  942  0.0  \n",
      "\n",
      "Métricas promedio:\n",
      "   AUC: 0.7442 ± 0.0035\n",
      "   ACCURACY: 0.6784 ± 0.0024\n",
      "   F1: 0.6400 ± 0.0042\n",
      "   TP: 1502.6000 ± 25.7449\n",
      "   FP: 924.8000 ± 29.3121\n",
      "   AMS: 0.0000 ± 0.0000\n",
      "Métricas fold 5: {'AUC': 0.7402362028519823, 'Accuracy': 0.6747859181731685, 'F1': 0.6372320101889195, 'TP': np.int64(1501), 'FP': np.int64(942), 'AMS': 0.0}\n",
      "\n",
      " Entrenamiento por folds completado\n",
      "\n",
      "\n",
      "Resultados por fold:\n",
      "   fold                        model_path       AUC  Accuracy        F1    TP  \\\n",
      "0     1  ../models/folds/model_fold_1.pkl  0.745541  0.679414  0.634252  1461   \n",
      "1     2  ../models/folds/model_fold_2.pkl  0.745128  0.681317  0.643389  1511   \n",
      "2     3  ../models/folds/model_fold_3.pkl  0.748758  0.678211  0.644225  1531   \n",
      "3     4  ../models/folds/model_fold_4.pkl  0.741234  0.678211  0.640900  1509   \n",
      "4     5  ../models/folds/model_fold_5.pkl  0.740236  0.674786  0.637232  1501   \n",
      "\n",
      "    FP  AMS  \n",
      "0  878  0.0  \n",
      "1  918  0.0  \n",
      "2  954  0.0  \n",
      "3  932  0.0  \n",
      "4  942  0.0  \n",
      "\n",
      "Métricas promedio:\n",
      "   AUC: 0.7442 ± 0.0035\n",
      "   ACCURACY: 0.6784 ± 0.0024\n",
      "   F1: 0.6400 ± 0.0042\n",
      "   TP: 1502.6000 ± 25.7449\n",
      "   FP: 924.8000 ± 29.3121\n",
      "   AMS: 0.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrenando con validación cruzada...\")\n",
    "\n",
    "results_df, features_all = train_with_folds(\n",
    "    folds_dir=folds_dir,\n",
    "    output_dir=\"../models/folds/\",\n",
    "    model_type=\"lightgbm\",  \n",
    "    top_k_features=15\n",
    ")\n",
    "\n",
    "print(\"\\nResultados por fold:\")\n",
    "print(results_df)\n",
    "\n",
    "if not results_df.empty:\n",
    "    print(f\"\\nMétricas promedio:\")\n",
    "    \n",
    "    numeric_cols = results_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col != 'fold':  \n",
    "            print(f\"   {col.upper().replace('_', '-')}: {results_df[col].mean():.4f} ± {results_df[col].std():.4f}\")\n",
    "else:\n",
    "    print(\"\\n No se generaron resultados de validación cruzada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb206833",
   "metadata": {},
   "source": [
    "## Entrenamiento con Validación Cruzada\n",
    "\n",
    "Entrena modelo en cada fold con:\n",
    "- Feature engineering automático\n",
    "- Feature selection (top-k por importancia)\n",
    "- Métricas: ROC-AUC, Accuracy, F1, AMS\n",
    "\n",
    "**ESTRATEGIA**: Voto Mayoritario en Features\n",
    "\n",
    "En lugar de elegir features manualmente, usamos un criterio estadístico:\n",
    "\n",
    "Seleccionamos variables que fueron importantes en la MAYORÍA de los folds.\n",
    " \n",
    "Ventajas:\n",
    " * Reduce overfitting (evita features inestables)\n",
    " * Mejora generalización\n",
    " * Reproducible y objetivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d87c5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANÁLISIS DE ESTABILIDAD DE FEATURES\n",
      "======================================================================\n",
      "\n",
      "Frecuencia de selección en los 5 folds:\n",
      "\n",
      "  MT_ll_met                      [█████] 5/5 folds\n",
      "  cluster_mass                   [█████] 5/5 folds\n",
      "  met_et                         [█████] 5/5 folds\n",
      "  mLL                            [█████] 5/5 folds\n",
      "  ptll_met                       [█████] 5/5 folds\n",
      "  E_sum_ll                       [█████] 5/5 folds\n",
      "  curr_mt                        [█████] 5/5 folds\n",
      "  lep_pt_1                       [█████] 5/5 folds\n",
      "  delta_R_ll                     [█████] 5/5 folds\n",
      "  pTll                           [█████] 5/5 folds\n",
      "  jet_pt                         [█████] 5/5 folds\n",
      "  pt_sum_ll                      [█████] 5/5 folds\n",
      "  lep_E_1                        [████░] 4/5 folds\n",
      "  pt_ratio                       [███░░] 3/5 folds\n",
      "  pt_balance                     [██░░░] 2/5 folds\n",
      "  jet_MV2c10                     [██░░░] 2/5 folds\n",
      "  lep_pt_0                       [██░░░] 2/5 folds\n",
      "  jet_eta                        [█░░░░] 1/5 folds\n",
      "  trigM                          [█░░░░] 1/5 folds\n",
      "\n",
      "======================================================================\n",
      "\n",
      "FEATURES SELECCIONADAS POR CONSENSO: 14\n",
      "   (Criterio: presentes en ≥3 folds)\n",
      "\n",
      "Features finales (ordenadas por estabilidad):\n",
      "   1.  MT_ll_met                 (5/5 folds)\n",
      "   2.  cluster_mass              (5/5 folds)\n",
      "   3.  met_et                    (5/5 folds)\n",
      "   4.  mLL                       (5/5 folds)\n",
      "   5.  ptll_met                  (5/5 folds)\n",
      "   6.  E_sum_ll                  (5/5 folds)\n",
      "   7.  curr_mt                   (5/5 folds)\n",
      "   8.  lep_pt_1                  (5/5 folds)\n",
      "   9.  delta_R_ll                (5/5 folds)\n",
      "  10.  pTll                      (5/5 folds)\n",
      "  11.  jet_pt                    (5/5 folds)\n",
      "  12.  pt_sum_ll                 (5/5 folds)\n",
      "  13.  lep_E_1                   (4/5 folds)\n",
      "  14.  pt_ratio                  (3/5 folds)\n",
      "\n",
      "Features guardadas en: models/final_features.json\n",
      "\n",
      "INSIGHT: Las features más estables son las que mejor generalizan\n",
      "   Features 5/5 folds = Extremadamente robustas (verde)\n",
      "   Features 4/5 folds = Muy robustas (amarillo)\n",
      "   Features 3/5 folds = Robustas (naranja)\n"
     ]
    }
   ],
   "source": [
    "flat = [f for sublist in features_all for f in sublist]\n",
    "counts = Counter(flat)\n",
    "\n",
    "print(\"ANÁLISIS DE ESTABILIDAD DE FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nFrecuencia de selección en los 5 folds:\\n\")\n",
    "\n",
    "# Mostrar todas las features ordenadas por frecuencia\n",
    "for feat, count in counts.most_common():\n",
    "    bar = \"█\" * count + \"░\" * (5 - count)\n",
    "    print(f\"  {feat:30s} [{bar}] {count}/5 folds\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# CRITERIO DE SELECCIÓN: Voto Mayoritario (≥3 de 5 folds)\n",
    "min_folds = 3 \n",
    "final_features = [feat for feat, c in counts.most_common() if c >= min_folds]\n",
    "\n",
    "print(f\"\\nFEATURES SELECCIONADAS POR CONSENSO: {len(final_features)}\")\n",
    "print(f\"   (Criterio: presentes en ≥{min_folds} folds)\\n\")\n",
    "\n",
    "print(\"Features finales (ordenadas por estabilidad):\")\n",
    "for i, (feat, count) in enumerate(counts.most_common(), 1):\n",
    "    if count >= min_folds:\n",
    "        stability = \"\" if count == 5 else \"\" if count == 4 else \"\"\n",
    "        print(f\"  {i:2d}. {stability} {feat:25s} ({count}/5 folds)\")\n",
    "\n",
    "\n",
    "import json\n",
    "with open(\"../models/final_features.json\", \"w\") as f:\n",
    "    json.dump(final_features, f, indent=2)\n",
    "    \n",
    "print(f\"\\nFeatures guardadas en: models/final_features.json\")\n",
    "print(f\"\\nINSIGHT: Las features más estables son las que mejor generalizan\")\n",
    "print(f\"   Features 5/5 folds = Extremadamente robustas (verde)\")\n",
    "print(f\"   Features 4/5 folds = Muy robustas (amarillo)\")\n",
    "print(f\"   Features 3/5 folds = Robustas (naranja)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452848d9",
   "metadata": {},
   "source": [
    "## Selección de Features con Estrategia de Consenso\n",
    "\n",
    "**Metodología: Voto Mayoritario**\n",
    "\n",
    "En lugar de seleccionar features manualmente, usamos un criterio estadístico:\n",
    "- Contamos cuántas veces cada feature fue seleccionada en los 5 folds\n",
    "- Seleccionamos solo las que aparecen en **≥3 folds** (mayoría)\n",
    "- Esto garantiza estabilidad y reduce overfitting\n",
    "\n",
    "**Ventajas:**\n",
    "- **Robustez**: Features inestables son descartadas automáticamente\n",
    "- **Generalización**: Mejor performance en datos no vistos\n",
    "- **Reproducibilidad**: Criterio objetivo y transparente\n",
    "\n",
    "**Clasificación de estabilidad:**\n",
    "- **5/5 folds**: Extremadamente robusta (siempre seleccionada)\n",
    "- **4/5 folds**: Muy robusta\n",
    "- **3/5 folds**: Robusta (mínimo aceptable)\n",
    "- **<3 folds**: Inestable (descartada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f150c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f24edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo final en dataset completo...\n",
      "\n",
      "\n",
      "Entrenamiento modelo final\n",
      "\n",
      "Entrenando modelo final con 14 featuresEntrenando modelo final con 14 features\n",
      "[LightGBM] [Info] Number of positive: 11340, number of negative: 14937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 26277, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431556 -> initscore=-0.275505\n",
      "[LightGBM] [Info] Start training from score -0.275505\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 11340, number of negative: 14937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 26277, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431556 -> initscore=-0.275505\n",
      "[LightGBM] [Info] Start training from score -0.275505\n",
      "Modelo final guardado en: ../models/best_model.pkl\n",
      "\n",
      " Modelo final guardado: models/best_model.pkl\n",
      "   Tipo: LightGBM\n",
      "   Features: 14\n",
      "   Dataset: 26,277 eventos\n",
      "Modelo final guardado en: ../models/best_model.pkl\n",
      "\n",
      " Modelo final guardado: models/best_model.pkl\n",
      "   Tipo: LightGBM\n",
      "   Features: 14\n",
      "   Dataset: 26,277 eventos\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrenando modelo final en dataset completo...\\n\")\n",
    "\n",
    "best_model = train_final_model(\n",
    "    merged_path=merged_path,\n",
    "    features_list=final_features,\n",
    "    model_type=\"lightgbm\",\n",
    "    output_path=\"../models/best_model.pkl\"\n",
    ")\n",
    "\n",
    "print(\"\\n Modelo final guardado: models/best_model.pkl\")\n",
    "print(f\"   Tipo: LightGBM\")\n",
    "print(f\"   Features: {len(final_features)}\")\n",
    "print(f\"   Dataset: {merged_df.shape[0]:,} eventos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d98fc",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo final\n",
    "\n",
    "Entrena modelo final en TODO el dataset con las features seleccionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "591df855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando feature engineering...\n",
      "Todas las 14 features disponibles\n",
      "\n",
      "Predicciones del modelo final (10 muestras aleatorias):\n",
      "\n",
      "   Real  Pred  Prob_Higgs  Correcto\n",
      "0     1     1    0.671631      True\n",
      "1     0     0    0.060787      True\n",
      "2     0     1    0.656003     False\n",
      "3     1     1    0.753134      True\n",
      "4     0     0    0.242721      True\n",
      "5     1     1    0.643601      True\n",
      "6     0     1    0.683979     False\n",
      "7     1     0    0.468636     False\n",
      "8     0     0    0.017518      True\n",
      "9     0     0    0.159764      True\n",
      "\n",
      "✓ Accuracy en muestra: 70.00%\n",
      "Todas las 14 features disponibles\n",
      "\n",
      "Predicciones del modelo final (10 muestras aleatorias):\n",
      "\n",
      "   Real  Pred  Prob_Higgs  Correcto\n",
      "0     1     1    0.671631      True\n",
      "1     0     0    0.060787      True\n",
      "2     0     1    0.656003     False\n",
      "3     1     1    0.753134      True\n",
      "4     0     0    0.242721      True\n",
      "5     1     1    0.643601      True\n",
      "6     0     1    0.683979     False\n",
      "7     1     0    0.468636     False\n",
      "8     0     0    0.017518      True\n",
      "9     0     0    0.159764      True\n",
      "\n",
      "✓ Accuracy en muestra: 70.00%\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"../models/best_model.pkl\")\n",
    "df_test = pd.read_pickle(merged_path)\n",
    "\n",
    "print(\"Aplicando feature engineering...\")\n",
    "df_test = add_feature_engineering(df_test)\n",
    "\n",
    "missing_features = [f for f in final_features if f not in df_test.columns]\n",
    "if missing_features:\n",
    "    print(f\"Features faltantes: {missing_features}\")\n",
    "    print(f\"   Usando solo features disponibles...\")\n",
    "    available_features = [f for f in final_features if f in df_test.columns]\n",
    "else:\n",
    "    available_features = final_features\n",
    "    print(f\"Todas las {len(final_features)} features disponibles\")\n",
    "\n",
    "sample_indices = df_test.sample(10, random_state=42).index\n",
    "X_sample = df_test.loc[sample_indices, available_features]\n",
    "y_sample = df_test.loc[sample_indices, 'target']\n",
    "\n",
    "probs = model.predict_proba(X_sample)[:, 1]\n",
    "preds = model.predict(X_sample)\n",
    "\n",
    "print(\"\\nPredicciones del modelo final (10 muestras aleatorias):\\n\")\n",
    "results_test = pd.DataFrame({\n",
    "    'Real': y_sample.values,\n",
    "    'Pred': preds,\n",
    "    'Prob_Higgs': probs\n",
    "})\n",
    "results_test['Correcto'] = results_test['Real'] == results_test['Pred']\n",
    "print(results_test)\n",
    "print(f\"\\n✓ Accuracy en muestra: {results_test['Correcto'].mean():.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
